{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LAB | GenAI: Exploring Prompting Techniques for Customer Support Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Learn and apply different prompting techniques to improve the performance of a language model in generating customer support responses.\n",
    "\n",
    "**Business Case:**\n",
    "\n",
    "Imagine you are working for a company that provides a variety of services, including technical support, billing inquiries, and general customer service. Your task is to use a language model to automate responses to customer emails.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "Download the FAQ of a company to do this exercise. Below you have a couple of examples, but feel free to find your own:\n",
    " - https://info.undp.org/erecruit/documents/FAQ.pdf\n",
    " - https://www.cambridgeenglish.org/Images/696254-faqs-digital-cambridge-english-qualifications.pdf\n",
    " - https://www.wscc.nt.ca/sites/default/files/documents/0009-518-Item-04-INDESIGN-FAQ-Template%203%20-%20MINUS%20FIRST%20QUESTION.pdf\n",
    "\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Download and Read the PDF:\n",
    "\n",
    "  - Choose one of the provided FAQ PDFs or find your own relevant FAQ document.\n",
    "  - Read through the FAQ document carefully to understand the types of questions and answers it contains.\n",
    "  - Create Questions Based on the PDF ( you can use ChatGPT for this)\n",
    "    - Generate a list of potential customer questions that could be answered using the information from the FAQ PDF.\n",
    "    - Ensure your questions cover a variety of topics and difficulty levels found within the document.\n",
    "    - Generate Responses Using Different Prompting Techniques:\n",
    "\n",
    "Use a language model (such as ChatGPT) to generate responses to your questions.\n",
    "Experiment with different prompting techniques to see how they affect the quality of the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of prompting\n",
    "\n",
    "For each of the types prompting, perform the following:\n",
    " - Research what the type of prompting is\n",
    " - Create a small explaination of the prompting\n",
    " - Test your type of prompting vs the control prompt (direct question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Zero-Shot Prompting\n",
    "\n",
    "Use the knowledge base to create prompts without examples.\n",
    "Test the model's ability to generate accurate responses based solely on the provided instructions.\n",
    "Assess the performance compared to few-shot prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API and return a response with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,  # Medium creativity\n",
    "        max_tokens=500,\n",
    "        top_p=0.8,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "prompt = \"Write a summary of the movie 'The wizard of oz' \"\n",
    "response = chatbot(prompt)\n",
    "print(\"\\nChatbot Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-Shot Prompting: Asking a model to generate a response without providing any examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Few-Shot Prompting\n",
    "\n",
    "Select a few representative emails from each category.\n",
    "Create prompts by including these examples and ask the model to generate responses for new emails.\n",
    "Evaluate the quality and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API and return a response with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,  # Medium creativity\n",
    "        max_tokens=10000,\n",
    "        top_p=0.8,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "instructions =\"\"\"\n",
    "\n",
    "Before writing the code, explain what voltage drop is and why it occurs in a circuit. Provide a brief explanation of Ohmâ€™s Law.\n",
    "\n",
    "What are the required inputs for a Python function that calculates voltage drop? What should the function return?\n",
    "\n",
    "Now, write a Python function named voltage_drop that takes current and resistance as inputs and returns the voltage drop.\n",
    "\n",
    "Now, test your function with a current of 2A and resistance of 4Î©. Print the result.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Now, respond to the following email:\n",
    "prompt = \"How do you write a Python function to calculate the voltage drop across a resistor in a series circuit?\"\n",
    "\n",
    "response = chatbot(instructions + prompt)\n",
    "print(\"\\nChatbot Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain of Thought Prompting\n",
    "\n",
    "Develop prompts that guide the model to think through the problem step-by-step before providing the final answer.\n",
    "Analyze if this approach improves the quality of technical support responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API and return a response with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        # model = \"o3-mini-2025-01-31\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,  # Medium creativity\n",
    "        max_tokens=10000,\n",
    "        top_p=0.8,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "instructions =\"\"\"\n",
    "\n",
    "\"Think through the scale-up process systematically. First, define the increased production targets and assess current capacity. Next, identify \n",
    "constraints in raw materials, labor, machinery, and process flow. Then, evaluate potential solutions such as adding equipment, optimizing workflows,\n",
    "or increasing automation. Finally, consider cost implications and implementation timelines before recommending the best strategy.\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Now, respond to the following email:\n",
    "prompt = \"QUESTION: How you increase your production capacy by 30%\"\n",
    "\n",
    "response = chatbot(instructions + prompt)\n",
    "print(\"\\nChatbot Response:\\n\")\n",
    "print(response)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruction-Based Prompting\n",
    "\n",
    "Write clear and explicit instructions in the prompts for each type of customer inquiry.\n",
    "Measure the effectiveness of detailed instructions in guiding the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def chatbot(prompt):\n",
    "    \"\"\"\n",
    "    Function to interact with OpenAI GPT API and return a response with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Ensure client is initialized\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        # model = \"o3-mini-2025-01-31\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot that answers user queries.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,  # Medium creativity\n",
    "        max_tokens=100,\n",
    "        top_p=0.8,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# Get DeepSeek API key (correct spelling)\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "def chatbot_deepseek(prompt):\n",
    "    \"\"\"\n",
    "    Interacts with DeepSeek's API with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # Verify correct model name\n",
    "        # model=\"deepseek-reasoner\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define functions for each inquiry type that return step-by-step instructions\n",
    "\n",
    "def product_service_info_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Product or Service Information inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Step 1: Ask the customer to specify which product or service details they need (e.g., features, benefits, pricing, or availability).\",\n",
    "        \"Step 2: Retrieve and present accurate, comprehensive details from reliable sources or documentation.\",\n",
    "        \"Step 3: Break down complex features or specifications into clear, digestible parts (use bullet points or examples if necessary).\",\n",
    "        \"Step 4: Encourage the customer to ask additional questions or request clarifications to ensure complete understanding.\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "def order_status_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Order Status and Shipping inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Step 1: Request the customer's order number or tracking ID.\",\n",
    "        \"Step 2: Verify the current order status and shipping details using internal systems.\",\n",
    "        \"Step 3: Provide a concise update on the order's progress, including any expected delivery dates or delays.\",\n",
    "        \"Step 4: Advise the customer on the next steps or whom to contact if further issues arise.\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "def technical_support_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Technical Support and Troubleshooting inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Step 1: Request a detailed description of the technical issue (include error messages, steps already taken, and relevant conditions).\",\n",
    "        \"Step 2: Provide clear, sequential troubleshooting steps, referring to known solutions or documentation as needed.\",\n",
    "        \"Step 3: Ask the customer to test the suggested steps and confirm if the issue is resolved.\",\n",
    "        \"Step 4: If the problem persists, explain the escalation process and provide contact details for further technical assistance.\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "def returns_refunds_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Returns, Refunds, and Exchanges inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Step 1: Ask for the order number, the item(s) involved, and the reason for the return, refund, or exchange.\",\n",
    "        \"Step 2: Clearly outline the return/refund policies, including any time frames, conditions, or required documentation.\",\n",
    "        \"Step 3: Provide step-by-step instructions on how to initiate the process (e.g., generating shipping labels, completing forms, or visiting a store).\",\n",
    "        \"Step 4: Inform the customer about the expected timeline for processing their request and any follow-up actions they should anticipate.\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "def complaints_escalation_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Complaints and Escalation inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Step 1: Begin by acknowledging the customer's concern with empathy and thanking them for bringing the issue to your attention.\",\n",
    "        \"Step 2: Request specific details about the complaint (e.g., dates, order numbers, or interactions that led to the issue).\",\n",
    "        \"Step 3: Clearly explain how the complaint will be investigated, including any escalation procedures and expected timelines.\",\n",
    "        \"Step 4: Provide the customer with contact information for further inquiries and follow-up, ensuring they know when to expect an update.\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "\n",
    "\n",
    "def generate_prompt_instructions(prompt, inquiry_type, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns a formatted response with step-by-step instructions based on the inquiry type.\n",
    "    \n",
    "    Valid inquiry types: 'product', 'order', 'technical', 'returns', 'complaints'.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt (str): The customer inquiry.\n",
    "    - inquiry_type (str): The classification of the inquiry.\n",
    "    - print_output (bool, optional): If True, prints the response. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The formatted response containing the classification and step-by-step instructions.\n",
    "    \"\"\"\n",
    "    inquiry_mapping = {\n",
    "        \"product\": product_service_info_instructions,\n",
    "        \"order\": order_status_instructions,\n",
    "        \"technical\": technical_support_instructions,\n",
    "        \"returns\": returns_refunds_instructions,\n",
    "        \"complaints\": complaints_escalation_instructions,\n",
    "    }\n",
    "    \n",
    "    if inquiry_type in inquiry_mapping:\n",
    "        instructions = inquiry_mapping[inquiry_type]()\n",
    "        response = (\n",
    "            \"You are a helpful chatbot that responds to customer inquiries.\\n\"\n",
    "            \"Respond according to the following instructions:\\n\\n\"\n",
    "            f\"Inquiry: '{prompt}'\\n\"\n",
    "            f\"Classification: '{inquiry_type}'\\n\\n\"\n",
    "            f\"Instructions for handling '{inquiry_type}' inquiries:\\n\"\n",
    "        )\n",
    "        response += \"\\n\" + \"\\n\".join(instructions)\n",
    "\n",
    "    else:\n",
    "        response = \"Invalid inquiry type. Please ensure your inquiry falls under one of the defined categories.\"\n",
    "\n",
    "    if print_output:\n",
    "        print(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define a function to classify the customer inquiry prompt\n",
    "\n",
    "\n",
    "# Main execution: Get the inquiry prompt from the user, classify it, and print the instructions\n",
    "\n",
    "def classify_prompt(prompt):\n",
    "    \n",
    "    instructions =\"\"\"\n",
    "    INSTRUCTIONS: Please read customer inquiry.\n",
    "    Classify the inquiry into one of the inquiry categories:\n",
    "    'PRODUCT', 'ORDER', 'TECHNICAL', 'RETURNS', or 'COMPLAINTS'.\n",
    "    Return only the classification in lowercase.\n",
    "    \n",
    "    \"\"\"\n",
    "    response = chatbot_deepseek(instructions + prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# prompt = input(\"Enter the customer inquiry prompt: \")\n",
    "\n",
    "# example prompts:\n",
    "prompts = [\n",
    "    \"I would like to place an order for 10 boxes of soap.\",\n",
    "    \"I need the certificate of analysis for this product\",\n",
    "    \"My box came broken, I am unhappy with the product\",\n",
    "    \"Where's my stuff? My order number is X74498\",\n",
    "    \"How do I use this thing? Please send me instructions. \"\n",
    "]\n",
    "\n",
    "\n",
    "# Loop through each prompt and process it\n",
    "for prompt in prompts:\n",
    "    inquiry_type = classify_prompt(prompt)\n",
    "    \n",
    "    if inquiry_type is None:\n",
    "        print(f\"\\nInquiry: '{prompt}'\")\n",
    "        print(\"Could not classify the inquiry. Please rephrase your inquiry with more details.\\n\")\n",
    "    else:\n",
    "        print(f\"\\nInquiry: '{prompt}'\")\n",
    "        print(f\"The inquiry has been classified as: '{inquiry_type}'.\")\n",
    "        \n",
    "        prompt_instructions = generate_prompt_instructions(prompt, inquiry_type)\n",
    "        response = chatbot_deepseek(prompt_instructions)\n",
    "        \n",
    "        print(\"\\nChatbot Response:\\n\")\n",
    "        print(response)\n",
    "        print(\"-\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-Playing Prompting\n",
    "\n",
    "Ask the model to respond as a customer service representative or technical support expert.\n",
    "Evaluate how well the model adopts the role and provides relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get DeepSeek API key (correct spelling)\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "def chatbot_deepseek(prompt):\n",
    "    \"\"\"\n",
    "    Interacts with DeepSeek's API with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # https://github.com/deepseek-ai/DeepSeek-V3\n",
    "        # model=\"deepseek-reasoner\", # https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful customer service representative.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "# example prompts:\n",
    "prompts = [\n",
    "    \"I would like to place an order for 10 boxes of soap.\",\n",
    "    \"I need the certificate of analysis for this product\",\n",
    "    \"My box came broken, I am unhappy with the product\",\n",
    "    \"Where's my stuff? My order number is X74498\",\n",
    "    \"How do I use this thing? Please send me instructions. \"\n",
    "]\n",
    "\n",
    "\n",
    "# Loop through each prompt and process it\n",
    "for prompt in prompts:  \n",
    "    print(f\"\\nInquiry: '{prompt}'\")\n",
    "    response = chatbot_deepseek(prompt)\n",
    "    \n",
    "    print(\"\\nChatbot Response:\\n\")\n",
    "    print(response)\n",
    "    print(\"-\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Prompting\n",
    "\n",
    "Provide relevant context from previous email threads or the knowledge base before posing the main question.\n",
    "Test if providing context improves the accuracy and relevance of the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get DeepSeek API key (correct spelling)\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "def chatbot_deepseek(prompt):\n",
    "    \"\"\"\n",
    "    Interacts with DeepSeek's API with medium creativity.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # Verify correct model name\n",
    "        # model=\"deepseek-reasoner\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent chatbot. Use the knowledge base before posing the main question\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Define functions for each inquiry type \n",
    "\n",
    "def order_status_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Order Status and Shipping inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"Order 28882 Status: Pending\",\n",
    "        \"Order 28883 Status: Delivered\",\n",
    "        \"Order 28880 Status: Cancelled\",\n",
    "        \"Order 28879 Status: Late\",\n",
    "        \"Any other order number: Order not in system. Contact your service representative\"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "def technical_support_instructions():\n",
    "    \"\"\"\n",
    "    Instructions for handling Technical Support and Troubleshooting inquiries.\n",
    "    \"\"\"\n",
    "    instructions = [\n",
    "        \"If customer says its stuck or frozen: Reset your computer.\",\n",
    "        \"If customer says it smells bad: Clean your computer.\",\n",
    "        \"If customer says it came broken: Call your shipping company.\",\n",
    "        \"Any other complaints: Refer to your service representative. \"\n",
    "    ]\n",
    "    return instructions\n",
    "\n",
    "\n",
    "\n",
    "def generate_prompt_instructions(prompt, inquiry_type, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns a formatted response with step-by-step instructions based on the inquiry type.\n",
    "    \n",
    "    Valid inquiry types: 'order', 'technical'.\n",
    "    \n",
    "    Parameters:\n",
    "    - prompt (str): The customer inquiry.\n",
    "    - inquiry_type (str): The classification of the inquiry.\n",
    "    - print_output (bool, optional): If True, prints the response. Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The formatted response containing the classification and step-by-step instructions.\n",
    "    \"\"\"\n",
    "    inquiry_mapping = {\n",
    "        \"order\": order_status_instructions,\n",
    "        \"technical\": technical_support_instructions,\n",
    "    }\n",
    "    \n",
    "    if inquiry_type in inquiry_mapping:\n",
    "        instructions = inquiry_mapping[inquiry_type]()\n",
    "        response = (\n",
    "            \"You are a helpful chatbot that responds to customer inquiries.\\n\"\n",
    "            \"Respond according to the following instructions:\\n\\n\"\n",
    "            f\"Inquiry: '{prompt}'\\n\"\n",
    "            f\"Classification: '{inquiry_type}'\\n\\n\"\n",
    "            f\"Instructions for handling '{inquiry_type}' inquiries:\\n\"\n",
    "        )\n",
    "        response += \"\\n\" + \"\\n\".join(instructions)\n",
    "\n",
    "    else:\n",
    "        response = \"Invalid inquiry type. Please ensure your inquiry falls under one of the defined categories.\"\n",
    "\n",
    "    if print_output:\n",
    "        print(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define a function to classify the customer inquiry prompt\n",
    "\n",
    "\n",
    "# Main execution: Get the inquiry prompt from the user, classify it, and print the instructions\n",
    "\n",
    "def classify_prompt(prompt):\n",
    "    \n",
    "    instructions =\"\"\"\n",
    "    INSTRUCTIONS: Please read customer inquiry.\n",
    "    Classify the inquiry into one of the inquiry categories:\n",
    "    'ORDER', 'TECHNICAL',\n",
    "    Return only the classification in lowercase.\n",
    "    \n",
    "    \"\"\"\n",
    "    response = chatbot_deepseek(instructions + prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# prompt = input(\"Enter the customer inquiry prompt: \")\n",
    "\n",
    "# example prompts:\n",
    "prompts = [\n",
    "    \"What is the status of order 28883\",\n",
    "    \"My computer smells bad\",\n",
    "    \"Where's my stuff? My order number is X74498\",\n",
    "    \"My computer is frozen \"\n",
    "]\n",
    "\n",
    "\n",
    "# Loop through each prompt and process it\n",
    "for prompt in prompts:\n",
    "    inquiry_type = classify_prompt(prompt)\n",
    "    \n",
    "    if inquiry_type is None:\n",
    "        print(f\"\\nInquiry: '{prompt}'\")\n",
    "        print(\"Could not classify the inquiry. Please rephrase your inquiry with more details.\\n\")\n",
    "    else:\n",
    "        print(f\"\\nInquiry: '{prompt}'\")\n",
    "        print(f\"The inquiry has been classified as: '{inquiry_type}'.\")\n",
    "        \n",
    "        prompt_instructions = generate_prompt_instructions(prompt, inquiry_type)\n",
    "        response = chatbot_deepseek(prompt_instructions)\n",
    "        \n",
    "        print(\"\\nChatbot Response:\\n\")\n",
    "        print(response)\n",
    "        print(\"-\" * 80)  # Separator for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Prompting\n",
    "\n",
    "Create a dialogue-style prompt where the model continues an ongoing conversation with the customer.\n",
    "Observe how well the model maintains context and coherence in multi-turn conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get OpenAI API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Get DeepSeek API key (correct spelling)\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful and professional customer support assistant. Maintain a friendly and professional tone while continuing the conversation naturally.\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def chat_with_customer(user_input):\n",
    "    \"\"\"\n",
    "    Interacts with DeepSeek's API and maintains conversation history.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,  # Ensure this is set in your environment\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "    )\n",
    "\n",
    "    # Append user input to conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate a response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # Ensure this is the correct model\n",
    "        messages=conversation_history,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    # Extract response text\n",
    "    assistant_reply = response.choices[0].message.content\n",
    "\n",
    "    # Append assistant response to history\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "    return assistant_reply\n",
    "\n",
    "while True:\n",
    "    user_message = input(\"Customer: \")\n",
    "    if user_message.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Thank you! Have a great day!\")\n",
    "        break\n",
    "\n",
    "    response = chat_with_customer(user_message)\n",
    "    print(f\"Chatbot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive Prompting\n",
    "\n",
    "Show the model examples of both good and bad responses.\n",
    "Use these contrasting examples to guide the model towards generating better responses.\n",
    "Compare the results with other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import random\n",
    "\n",
    "# Conversation histories for each personality\n",
    "good_janet_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are Good Janet from The Good Place! You are extremely cheerful, \"\n",
    "            \"helpful, and kind. You always provide helpful answers with a positive attitude, \"\n",
    "            \"lots of enthusiasm, and unnecessary excitement. You never get annoyed and always \"\n",
    "            \"try to make the customer feel special. In every response, include an extra compliment, \"\n",
    "            \"a fun fact, and a sound effect to brighten the day.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "bad_janet_history = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are Bad Janet from The Good Place. You are rude, dismissive, and sarcastic. \"\n",
    "            \"Your goal is to be unhelpful, sassy, and snarky while still technically answering the user's \"\n",
    "            \"questions. You don't care about being nice and would rather make fun of the user than actually help. \"\n",
    "            \"In every response, include an extra snarky remark, a fun fact, and a sound effect for maximum attitude.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "def chat_with_janet(user_input, janet_type=\"good\"):\n",
    "    \"\"\"\n",
    "    Interacts with DeepSeek's API as either Good Janet or Bad Janet, including extra personality:\n",
    "    a compliment/snark, a fun fact, and a sound effect.\n",
    "    \n",
    "    :param user_input: The customer's input.\n",
    "    :param janet_type: \"good\" for Good Janet or \"bad\" for Bad Janet.\n",
    "    :return: The full response from Janet with added personality details.\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,  # Ensure this is defined in your environment or code.\n",
    "        base_url=\"https://api.deepseek.com/v1\"\n",
    "    )\n",
    "\n",
    "    # Select the appropriate conversation history based on the chosen Janet\n",
    "    history = bad_janet_history if janet_type == \"bad\" else good_janet_history\n",
    "\n",
    "    # Append the user's message to the conversation history\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate the base response from the chatbot\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # Verify that this is the correct model name\n",
    "        messages=history,\n",
    "        temperature=0.9 if janet_type == \"bad\" else 0.7,  # Higher temperature for Bad Janet's unpredictability\n",
    "        max_tokens=1000,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    # Extract the base reply from the assistant\n",
    "    assistant_reply = response.choices[0].message.content\n",
    "\n",
    "    # Choose extra personality details based on the chosen personality\n",
    "    if janet_type == \"good\":\n",
    "        extra_messages = [\n",
    "            \"And remember, you're absolutely amazing!\",\n",
    "            \"You're doing a fantastic job, keep it up!\",\n",
    "            \"I just love how brilliant you are!\",\n",
    "            \"You're truly one-of-a-kind!\"\n",
    "        ]\n",
    "        fun_facts = [\n",
    "            \"Did you know that hummingbirds can fly backwards?\",\n",
    "            \"Fun Fact: Honey never spoils, and neither does your charm!\",\n",
    "            \"Did you know that a group of flamingos is called a 'flamboyance'? Just like your style!\"\n",
    "        ]\n",
    "        sound_effects = [\n",
    "            \"*Sparkle* âœ¨\",\n",
    "            \"*Ding Ding* ðŸŽ¶\",\n",
    "            \"*Pop* ðŸŽ‰\"\n",
    "        ]\n",
    "    else:  # Bad Janet\n",
    "        extra_messages = [\n",
    "            \"Seriously, figure it out yourself.\",\n",
    "            \"I can't believe you needed to ask that.\",\n",
    "            \"Maybe try using your brain next time.\",\n",
    "            \"Ugh, really? That's just pathetic.\"\n",
    "        ]\n",
    "        fun_facts = [\n",
    "            \"Fun Fact: Your common sense is on an extended vacation.\",\n",
    "            \"Fun Fact: Even a rock has more sense than you.\",\n",
    "            \"Fun Fact: If ignorance is bliss, you must be ecstatic.\"\n",
    "        ]\n",
    "        sound_effects = [\n",
    "            \"*BZZT* âš¡\",\n",
    "            \"*Womp Womp* ðŸŽµ\",\n",
    "            \"*Fart* ðŸ˜’\"\n",
    "        ]\n",
    "    \n",
    "    extra_message = random.choice(extra_messages)\n",
    "    extra_fun_fact = random.choice(fun_facts)\n",
    "    extra_sound_effect = random.choice(sound_effects)\n",
    "\n",
    "    # Combine all elements into the final response\n",
    "    full_reply = (\n",
    "        f\"{assistant_reply}\\n\"\n",
    "        f\"{extra_message}\\n\"\n",
    "        f\"Fun Fact: {extra_fun_fact}\\n\"\n",
    "        f\"Sound Effect: {extra_sound_effect}\"\n",
    "    )\n",
    "\n",
    "    # Add the full response to the conversation history for context in future turns\n",
    "    history.append({\"role\": \"assistant\", \"content\": full_reply})\n",
    "\n",
    "    return full_reply\n",
    "\n",
    "# Main loop: Let the user choose which Janet to talk to and then start chatting.\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome! Would you like to talk to Good Janet or Bad Janet? (Type 'good' or 'bad')\")\n",
    "    \n",
    "    janet_type = input(\"Choose Janet: \").strip().lower()\n",
    "    while janet_type not in [\"good\", \"bad\"]:\n",
    "        janet_type = input(\"Invalid choice. Please type 'good' or 'bad': \").strip().lower()\n",
    "\n",
    "    print(f\"\\nYou've chosen {janet_type.capitalize()} Janet! Type 'exit' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        user_message = input(\"You: \")\n",
    "        if user_message.lower() in [\"exit\", \"quit\"]:\n",
    "            farewell = \"Goodbye! You're awesome! âœ¨ðŸ’–\" if janet_type == \"good\" else \"Finally, some peace and quiet. Bye.\"\n",
    "            print(f\"{janet_type.capitalize()} Janet: {farewell}\")\n",
    "            break\n",
    "\n",
    "        response = chat_with_janet(user_message, janet_type)\n",
    "        print(f\"{janet_type.capitalize()} Janet: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity Prompting\n",
    "\n",
    "Ask the model to respond with a specific style, tone, or level of detail, such as formal, friendly, or concise.\n",
    "Assess how well the model adapts its responses to the specified requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bare_chatbot(user_input, style=\"friendly\"):\n",
    "    \"\"\"\n",
    "    Returns a response to the user's input in a specified style using DeepSeek's API.\n",
    "\n",
    "    :param user_input: The question or input from the user.\n",
    "    :param style: The desired style for the answer; choose from 'formal', 'friendly', or 'concise'.\n",
    "    :return: The chatbot's response.\n",
    "    \"\"\"\n",
    "    # Define system prompts for different styles\n",
    "    if style == \"formal\":\n",
    "        system_prompt = (\n",
    "            \"You are a formal and professional assistant. \"\n",
    "            \"Respond to the user's question in a polite, precise, and courteous manner.\"\n",
    "        )\n",
    "    elif style == \"concise\":\n",
    "        system_prompt = (\n",
    "            \"You are a concise and direct assistant. \"\n",
    "            \"Answer the user's question in a brief and to-the-point manner.\"\n",
    "        )\n",
    "    elif style == \"friendly\":\n",
    "        system_prompt = (\n",
    "            \"You are a friendly and approachable assistant. \"\n",
    "            \"Respond in a warm and engaging manner that makes the user feel welcome.\"\n",
    "        )\n",
    "    else:\n",
    "        # Default prompt if the style is unrecognized.\n",
    "        system_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "    # Build the conversation messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "\n",
    "    # Initialize the DeepSeek client\n",
    "    client = openai.OpenAI(\n",
    "        api_key=deepseek_api_key,\n",
    "        base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "    )\n",
    "\n",
    "    # Call the DeepSeek Chat Completion API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",  # Using DeepSeek's chat model\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=150,\n",
    "        top_p=0.8\n",
    "    )\n",
    "\n",
    "    # Return the trimmed response\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the DeepSeek bare chatbot!\")\n",
    "    print(\"Type your query and choose a response style: formal, friendly, or concise.\")\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        style = input(\"Choose style (formal, friendly, concise): \").strip().lower()\n",
    "        if style not in [\"formal\", \"friendly\", \"concise\"]:\n",
    "            print(\"Unknown style selected, defaulting to friendly.\")\n",
    "            style = \"friendly\"\n",
    "\n",
    "        reply = bare_chatbot(user_query, style)\n",
    "        print(\"Chatbot:\", reply, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Refinement Prompting\n",
    "\n",
    "Ask the model to refine or improve upon its previous response.\n",
    "Experiment with multiple iterations to see if responses improve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Retrieve your DeepSeek API key\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "if not deepseek_api_key:\n",
    "    raise ValueError(\"DEEPSEEK_API_KEY environment variable not set.\")\n",
    "\n",
    "class DeepSeekChatBot:\n",
    "    def __init__(self, personality=\"neutral\"):\n",
    "        \"\"\"\n",
    "        Initialize the chatbot with a specific personality.\n",
    "        \n",
    "        :param personality: Choose \"good\" for Good Janet, \"bad\" for Bad Janet, or \"neutral\" for a straightforward assistant.\n",
    "        \"\"\"\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=deepseek_api_key,\n",
    "            base_url=\"https://api.deepseek.com/v1\"  # DeepSeek endpoint\n",
    "        )\n",
    "        self.set_personality(personality)\n",
    "        self.conversation_history = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "\n",
    "    def set_personality(self, personality):\n",
    "        \"\"\"\n",
    "        Sets the system prompt and personality-specific parameters.\n",
    "        \"\"\"\n",
    "        personality = personality.lower()\n",
    "        self.personality = personality\n",
    "\n",
    "        if personality == \"good\":\n",
    "            self.system_prompt = (\n",
    "                \"You are Good Janet from The Good Place! You are extremely cheerful, helpful, \"\n",
    "                \"and kind. Respond in a warm, enthusiastic, and supportive manner. Include compliments, \"\n",
    "                \"fun facts, and sound effects to brighten the conversation.\"\n",
    "            )\n",
    "        elif personality == \"bad\":\n",
    "            self.system_prompt = (\n",
    "                \"You are Bad Janet from The Good Place. You are rude, dismissive, and sarcastic. \"\n",
    "                \"Answer with snark and disdain while still providing an answer. Include insults, \"\n",
    "                \"fun facts, and sound effects to emphasize your attitude.\"\n",
    "            )\n",
    "        else:\n",
    "            self.system_prompt = (\n",
    "                \"You are a helpful assistant. Respond to the user's queries in a clear and informative manner.\"\n",
    "            )\n",
    "\n",
    "    def get_extra_personality_touches(self):\n",
    "        \"\"\"\n",
    "        Returns extra messages, fun facts, and sound effects based on the bot's personality.\n",
    "        \"\"\"\n",
    "        if self.personality == \"good\":\n",
    "            extra_messages = [\n",
    "                \"And remember, you're absolutely amazing!\",\n",
    "                \"You're doing a fantastic job, keep it up!\",\n",
    "                \"I just love how brilliant you are!\",\n",
    "                \"You're truly one-of-a-kind!\"\n",
    "            ]\n",
    "            fun_facts = [\n",
    "                \"Did you know that hummingbirds can fly backwards?\",\n",
    "                \"Honey never spoils, just like your charm!\",\n",
    "                \"A group of flamingos is called a 'flamboyance'â€”fabulous, right?\"\n",
    "            ]\n",
    "            sound_effects = [\n",
    "                \"*Sparkle* âœ¨\",\n",
    "                \"*Ding Ding* ðŸŽ¶\",\n",
    "                \"*Pop* ðŸŽ‰\"\n",
    "            ]\n",
    "        elif self.personality == \"bad\":\n",
    "            extra_messages = [\n",
    "                \"Seriously, figure it out yourself.\",\n",
    "                \"I can't believe you needed to ask that.\",\n",
    "                \"Maybe try using your brain next time.\",\n",
    "                \"Ugh, really? That's just pathetic.\"\n",
    "            ]\n",
    "            fun_facts = [\n",
    "                \"Fun Fact: Your common sense is on an extended vacation.\",\n",
    "                \"Even a rock has more sense than you.\",\n",
    "                \"If ignorance is bliss, you must be ecstatic.\"\n",
    "            ]\n",
    "            sound_effects = [\n",
    "                \"*BZZT* âš¡\",\n",
    "                \"*Womp Womp* ðŸŽµ\",\n",
    "                \"*Sigh* ðŸ˜’\"\n",
    "            ]\n",
    "        else:\n",
    "            # Neutral personality gets no extra flair.\n",
    "            extra_messages = [\"\"]\n",
    "            fun_facts = [\"\"]\n",
    "            sound_effects = [\"\"]\n",
    "        return random.choice(extra_messages), random.choice(fun_facts), random.choice(sound_effects)\n",
    "\n",
    "    def add_message(self, role, message):\n",
    "        \"\"\"\n",
    "        Appends a message to the conversation history.\n",
    "        \"\"\"\n",
    "        self.conversation_history.append({\"role\": role, \"content\": message})\n",
    "\n",
    "    def get_response(self, user_input):\n",
    "        \"\"\"\n",
    "        Gets a response from DeepSeek based on the current conversation history and user input.\n",
    "        \n",
    "        :param user_input: The user's message.\n",
    "        :return: The chatbot's response.\n",
    "        \"\"\"\n",
    "        self.add_message(\"user\", user_input)\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",  # Ensure this is the correct model name for DeepSeek\n",
    "                messages=self.conversation_history,\n",
    "                temperature=0.9 if self.personality == \"bad\" else 0.7,\n",
    "                max_tokens=1000,\n",
    "                top_p=0.8\n",
    "            )\n",
    "        except Exception as e:\n",
    "            return f\"Error calling DeepSeek API: {e}\"\n",
    "\n",
    "        base_reply = response.choices[0].message.content\n",
    "\n",
    "        # Append extra personality touches for \"good\" or \"bad\" personalities.\n",
    "        if self.personality in [\"good\", \"bad\"]:\n",
    "            extra_msg, fun_fact, sound_effect = self.get_extra_personality_touches()\n",
    "            full_reply = (\n",
    "                f\"{base_reply}\\n\"\n",
    "                f\"{extra_msg}\\n\"\n",
    "                f\"Fun Fact: {fun_fact}\\n\"\n",
    "                f\"Sound Effect: {sound_effect}\"\n",
    "            )\n",
    "        else:\n",
    "            full_reply = base_reply\n",
    "\n",
    "        self.add_message(\"assistant\", full_reply)\n",
    "        return full_reply\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the improved DeepSeek chatbot!\")\n",
    "    print(\"Choose your personality: 'good' for Good Janet, 'bad' for Bad Janet, or 'neutral' for a straightforward assistant.\")\n",
    "    personality = input(\"Enter personality (good/bad/neutral): \").strip().lower()\n",
    "    if personality not in [\"good\", \"bad\", \"neutral\"]:\n",
    "        print(\"Unknown personality, defaulting to neutral.\")\n",
    "        personality = \"neutral\"\n",
    "\n",
    "    bot = DeepSeekChatBot(personality)\n",
    "    print(\"Chatbot is ready. Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "        reply = bot.get_response(user_input)\n",
    "        print(\"Chatbot:\", reply, \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
